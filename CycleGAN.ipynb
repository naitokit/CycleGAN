{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CycleGAN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"apHPpm64N3-w","colab_type":"code","outputId":"db58a4a9-086a-4fc4-e199-5a4b668d680b","executionInfo":{"status":"ok","timestamp":1566269203038,"user_tz":-540,"elapsed":29592,"user":{"displayName":"北島直人","photoUrl":"","userId":"13780393757979971033"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r64p5qlnjsG6","colab_type":"code","outputId":"e3a01f63-c032-4f7d-badf-ff8c1344bd6c","executionInfo":{"status":"ok","timestamp":1566268564731,"user_tz":-540,"elapsed":2179,"user":{"displayName":"北島直人","photoUrl":"","userId":"13780393757979971033"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from __future__ import print_function, division\n","import scipy\n","# from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model, model_from_json\n","from keras.optimizers import Adam\n","import datetime\n","import matplotlib.pyplot as plt\n","import sys\n","import numpy as np\n","import os\n","from PIL import Image"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"arrvgLxuPIJ8","colab_type":"code","colab":{}},"source":["class CycleGAN():\n","  def __init__(self):\n","    # Input shape\n","    self.img_rows = 128\n","    self.img_cols = 128\n","    self.channels = 3\n","    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","    self.dir_path = './' + 'drive' + '/' + 'My Drive/' + '授業資料/' + 'M1/' + 'Pattern_Recognision_and_Machine_Learning/' + '後半/' + 'cifar-10/' + 'cifar-10/'\n","\n","    # Calculate output shape of D (PatchGAN)\n","    self.patch = int(self.img_rows / 2**4)\n","    self.disc_patch = (patch, patch, 1)\n","\n","    # Number of filters in the first layer of G and D\n","    self.gf = 32\n","    self.df = 64\n","\n","    # Loss weights\n","    self.lambda_cycle = 10.0                    # Cycle-consistency loss\n","    self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n","\n","    optimizer = Adam(0.0002, 0.5)\n","\n","    # Build and compile the discriminators\n","    self.d_A = self.build_discriminator()\n","    self.d_B = self.build_discriminator()\n","    self.d_A.compile(loss='mse',\n","        optimizer=optimizer,\n","        metrics=['accuracy'])\n","    self.d_B.compile(loss='mse',\n","        optimizer=optimizer,\n","        metrics=['accuracy'])\n","\n","    #-------------------------\n","    # Construct Computational\n","    #   Graph of Generators\n","    #-------------------------\n","\n","    # Build the generators\n","    self.g_AB = self.build_generator()\n","    self.g_BA = self.build_generator()\n","\n","    # Input images from both domains\n","    img_A = Input(shape=self.img_shape)\n","    img_B = Input(shape=self.img_shape)\n","\n","    # Translate images to the other domain\n","    fake_B = self.g_AB(img_A)\n","    fake_A = self.g_BA(img_B)\n","    # Translate images back to original domain\n","    reconstr_A = self.g_BA(fake_B)\n","    reconstr_B = self.g_AB(fake_A)\n","    # Identity mapping of images\n","    img_A_id = self.g_BA(img_A)\n","    img_B_id = self.g_AB(img_B)\n","\n","    # For the combined model we will only train the generators\n","    self.d_A.trainable = False\n","    self.d_B.trainable = False\n","\n","    # Discriminators determines validity of translated images\n","    valid_A = self.d_A(fake_A)\n","    valid_B = self.d_B(fake_B)\n","\n","    # Combined model trains generators to fool discriminators\n","    self.combined = Model(inputs=[img_A, img_B],\n","                          outputs=[ valid_A, valid_B,\n","                                    reconstr_A, reconstr_B,\n","                                    img_A_id, img_B_id ])\n","    self.combined.compile(loss=['mse', 'mse',\n","                                'mae', 'mae',\n","                                'mae', 'mae'],\n","                        loss_weights=[  1, 1,\n","                                        self.lambda_cycle, self.lambda_cycle,\n","                                        self.lambda_id, self.lambda_id ],\n","                        optimizer=optimizer)\n","\n","  def build_generator(self):\n","    \"\"\"U-Net Generator\"\"\"\n","    \n","    def conv2d(layer_input, filters, f_size=4):\n","      \"\"\"Layers used during downsampling\"\"\"\n","      d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","      d = LeakyReLU(alpha=0.2)(d)\n","  #         d = InstanceNormalization()(d)\n","      return d\n","\n","    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n","      \"\"\"Layers used during upsampling\"\"\"\n","      u = UpSampling2D(size=2)(layer_input)\n","      u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","      if dropout_rate:\n","        u = Dropout(dropout_rate)(u)\n","      #       u = InstanceNormalization()(u)\n","      u = Concatenate()([u, skip_input])\n","      return u\n","\n","    # Image input\n","    d0 = Input(shape=self.img_shape)\n","    # Downsampling\n","    d1 = conv2d(d0, self.gf)    \n","    d2 = conv2d(d1, self.gf*2)    \n","    d3 = conv2d(d2, self.gf*4)    \n","    d4 = conv2d(d3, self.gf*8)    \n","\n","    # Upsampling\n","    u1 = deconv2d(d4, d3, self.gf*4)\n","    u2 = deconv2d(u1, d2, self.gf*2)\n","    u3 = deconv2d(u2, d1, self.gf)\n","\n","    u4 = UpSampling2D(size=2)(u3)\n","    output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n","\n","    return Model(d0, output_img)\n","\n","  def build_discriminator(self):\n","\n","    def d_layer(layer_input, filters, f_size=4, normalization=True):\n","      \"\"\"Discriminator layer\"\"\"\n","      d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","      d = LeakyReLU(alpha=0.2)(d)\n","  #         if normalization:\n","  #             d = InstanceNormalization()(d)\n","      return d\n","\n","    img = Input(shape=self.img_shape)\n","\n","    d1 = d_layer(img, self.df, normalization=False)\n","    d2 = d_layer(d1, self.df*2)\n","    d3 = d_layer(d2, self.df*4)\n","    d4 = d_layer(d3, self.df*8)\n","\n","    validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","    return Model(img, validity)\n","\n","  def train(self, epochs, train_nums, batch_size=1):\n","    valid = np.ones((train_nums,) + self.disc_patch)\n","    fake = np.zeros((train_nums,) + self.disc_patch)\n","\n","    for epoch in range(epochs):\n","      imgs_A, imgs_B = self.data_read(con='train',n_data=train_nums)\n","      \n","#     Translate images to opposite domain\n","      fake_B = self.g_AB.predict(imgs_A)\n","      fake_A = self.g_BA.predict(imgs_B)\n","\n","      # Train the discriminators (original images = real / translated = Fake)\n","      dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n","      dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n","      dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n","\n","      dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n","      dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n","      dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n","\n","      # Total disciminator loss\n","      d_loss = 0.5 * np.add(dA_loss, dB_loss)\n","\n","\n","      # ------------------\n","      #  Train Generators\n","      # ------------------\n","\n","      # Train the generators\n","      g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n","                                      [valid, valid,\n","                                      imgs_A, imgs_B,\n","                                      imgs_A, imgs_B])\n","      print('epochs:{0}'.format(epoch))\n","      print('discriminator loss:{0}'.format(d_loss))           \n","      print('generator loss:{0}'.format(g_loss))           \n","\n","  def generate(self,data_num,load):\n","    r, c = 2, 3\n","    imgs_A, imgs_B = self.data_read(con='test',n_data=data_num)\n","    \n","    if load == True:\n","      dir_path_name_model = self.dir_path + 'g_AB_model.json'\n","      dir_path_name_weights = self.dir_path + 'g_AB_weights.h5'\n","      # g_ABモデルを読み込む\n","      g_AB = model_from_json(open(dir_path_name_model).read())\n","      # 学習結果を読み込む\n","      g_AB.load_weights(dir_path_name_weights)\n","#       g_AB.summary()\n","#       g_AB.compile(loss='categorical_crossentropy',\n","#               optimizer='rmsprop',\n","#               metrics=['accuracy'])\n","      \n","      dir_path_name_model = self.dir_path + 'g_BA_model.json'\n","      dir_path_name_weights = self.dir_path + 'g_BA_weights.h5'\n","      # g_BAモデルを読み込む\n","      g_BA = model_from_json(open(dir_path_name_model).read())\n","      # 学習結果を読み込む\n","      g_BA.load_weights(dir_path_name_weights)\n","\n","    # Translate images to the other domain\n","    fakes_B = self.g_AB.predict(imgs_A)\n","    fakes_A = self.g_BA.predict(imgs_B)\n","\n","    # Translate back to original domain\n","    reconstrs_A = self.g_BA.predict(fakes_B)\n","    reconstrs_B = self.g_AB.predict(fakes_A)\n","    \n","#     print('imgs_A:{0}'.format(imgs_A.shape))\n","#     print('fakes_B:{0}'.format(fakes_B.shape))\n","#     print('reconst_A:{0}'.format(reconstrs_A.shape))\n","    \n","    for i in range(data_num):\n","      gen_imgs = np.stack([imgs_A[i], fakes_B[i], reconstrs_A[i], imgs_B[i], fakes_A[i], reconstrs_B[i]])\n","      \n","      print('gen:{0}'.format(gen_imgs.shape))\n","\n","      # Rescale images 0 - 1\n","      gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","      titles = ['Original', 'Translated', 'Reconstructed']\n","      fig, axs = plt.subplots(r, c)\n","      cnt = 0\n","      for j in range(r):\n","        for k in range(c):\n","#               print(gen_imgs[cnt].shape)\n","              axs[j,k].imshow(gen_imgs[cnt])\n","              axs[j, k].set_title(titles[k])\n","              axs[j,k].axis('off')\n","              cnt += 1\n","      gen_path_name = self.dir_path + 'result' + '/' + 'generate_' + str(i) + '.png'\n","      print(i)\n","      fig.savefig(gen_path_name)\n","      plt.close()\n","\n","  def data_read(self,con,n_data):\n","    if con == \"train\":\n","        dir_path_2 = self.dir_path + 'train'\n","    elif con == \"test\":\n","        dir_path_2 = self.dir_path + 'test'\n","\n","    imgs_A = np.zeros([n_data,self.img_rows,self.img_rows,self.channels])\n","    imgs_B = np.zeros([n_data,self.img_rows,self.img_rows,self.channels])\n","\n","    for i in range(n_data):\n","      img_A = dir_path_2 + '/' + 'airplane' + '/' + str(i) + '.png'\n","      img_B = dir_path_2 + '/' + 'automobile' + '/' + str(i) + '.png'\n","      work_img_A = Image.open(img_A).convert('RGB')\n","      resize_img_A = work_img_A.resize((self.img_rows, self.img_rows))\n","      work_img_B = Image.open(img_B).convert('RGB')\n","      resize_img_B = work_img_B.resize((self.img_rows, self.img_rows))\n","      data_vec_A = np.asarray(resize_img_A).astype(np.float64)\n","      data_vec_B = np.asarray(resize_img_B).astype(np.float64)\n","#       if i == 0:\n","#         print('data_vec_A:{0}'.format(data_vec_A))\n","      data_vec_A = data_vec_A / 255.0\n","      data_vec_B = data_vec_B / 255.0\n","#       if i == 0:\n","#         print('data_vec_A:{0}'.format(data_vec_A.shape))\n","#       data_vec_B = data_vec_A / np.sum( data_vec_A )\n","#       data_vec_B = data_vec_B / np.sum( data_vec_B )\n","\n","      imgs_A[i] = data_vec_A\n","      imgs_B[i] = data_vec_B\n","    \n","    return imgs_A, imgs_B\n","\n","  def save_model(self):\n","    # モデルとパラメタを別々に保存\n","    dir_path_name_model = self.dir_path + 'g_AB_model.json'\n","    dir_path_name_weights = self.dir_path + 'g_AB_weights.h5'\n","    g_AB_json = self.g_AB.to_json()\n","    open(dir_path_name_model, 'w').write(g_AB_json)\n","    self.g_AB.save_weights(dir_path_name_weights)\n","    \n","    dir_path_name_model = self.dir_path + 'g_BA_model.json'\n","    dir_path_name_weights = self.dir_path + 'g_BA_weights.h5'\n","    g_BA_json = self.g_BA.to_json()\n","    open(dir_path_name_model, 'w').write(g_BA_json)\n","    self.g_BA.save_weights(dir_path_name_weights)\n","gan = CycleGAN()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pvfKkktpU3RA","colab_type":"code","outputId":"f4b79915-1098-4a88-af14-6c0802b6d0a3","executionInfo":{"status":"ok","timestamp":1566269684844,"user_tz":-540,"elapsed":425217,"user":{"displayName":"北島直人","photoUrl":"","userId":"13780393757979971033"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# print(gan.g_AB.summary())\n","gan.train(epochs=100, train_nums=100, batch_size=1)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["W0820 02:49:14.767649 140054762952576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0820 02:49:14.781833 140054762952576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["epochs:0\n","discriminator loss:[0.4868436 0.5      ]\n","generator loss:[13.102646, 0.99825865, 0.97831094, 0.5465702, 0.4503237, 0.68185335, 0.4752836]\n","epochs:1\n","discriminator loss:[0.14851294 0.75109375]\n","generator loss:[12.450613, 1.1244599, 1.1442883, 0.49020985, 0.41987824, 0.6171743, 0.46380994]\n","epochs:2\n","discriminator loss:[0.6890434  0.67636716]\n","generator loss:[9.7731, 1.1599498, 1.0384514, 0.3058384, 0.36759537, 0.43137607, 0.40898427]\n","epochs:3\n","discriminator loss:[0.3523541 0.5020703]\n","generator loss:[11.226782, 0.66909736, 0.9930671, 0.34335232, 0.5305711, 0.30523738, 0.52014554]\n","epochs:4\n","discriminator loss:[0.4030725  0.35242188]\n","generator loss:[8.538177, 0.9104491, 0.5425303, 0.38183373, 0.25935757, 0.4144882, 0.2587966]\n","epochs:5\n","discriminator loss:[0.2405057 0.5788281]\n","generator loss:[7.359299, 0.90901303, 0.8925861, 0.23617052, 0.24377173, 0.4736966, 0.28458083]\n","epochs:6\n","discriminator loss:[0.1792547 0.7081641]\n","generator loss:[7.587137, 0.99103624, 0.9657358, 0.25667036, 0.23424362, 0.36594966, 0.35527587]\n","epochs:7\n","discriminator loss:[0.12379208 0.8239844 ]\n","generator loss:[6.3583922, 1.3679123, 0.813567, 0.17742716, 0.17694353, 0.32348225, 0.30972368]\n","epochs:8\n","discriminator loss:[0.24852288 0.67863286]\n","generator loss:[7.8383484, 2.4423878, 0.73695844, 0.21687263, 0.20094995, 0.25545365, 0.22532205]\n","epochs:9\n","discriminator loss:[0.47173315 0.33359376]\n","generator loss:[6.789659, 0.5734851, 0.6516754, 0.2624954, 0.24230418, 0.31053084, 0.20597212]\n","epochs:10\n","discriminator loss:[0.41224945 0.3835547 ]\n","generator loss:[6.315764, 0.6657811, 0.46038425, 0.2839704, 0.18797688, 0.28029788, 0.18982784]\n","epochs:11\n","discriminator loss:[0.35522544 0.49585938]\n","generator loss:[6.810148, 0.60691756, 0.55357116, 0.2796818, 0.23956469, 0.269737, 0.18745679]\n","epochs:12\n","discriminator loss:[0.45553237 0.21796875]\n","generator loss:[9.0580015, 0.48872182, 0.49159345, 0.3546995, 0.4005146, 0.28703368, 0.23851123]\n","epochs:13\n","discriminator loss:[0.3505595 0.4995703]\n","generator loss:[6.1066165, 0.56571054, 0.64562714, 0.22792242, 0.22472697, 0.20294653, 0.16583839]\n","epochs:14\n","discriminator loss:[0.34100989 0.4960547 ]\n","generator loss:[5.5696106, 0.52831894, 0.6229034, 0.22476298, 0.18102877, 0.18918732, 0.17128305]\n","epochs:15\n","discriminator loss:[0.40181214 0.2852344 ]\n","generator loss:[5.6201687, 0.402995, 0.47612926, 0.23123516, 0.20468244, 0.22850412, 0.15336409]\n","epochs:16\n","discriminator loss:[0.3092038  0.46410155]\n","generator loss:[4.5157013, 0.5191674, 0.4724711, 0.15450308, 0.16711774, 0.1489014, 0.15895338]\n","epochs:17\n","discriminator loss:[0.33517817 0.39527345]\n","generator loss:[4.117153, 0.48937222, 0.43534166, 0.1512061, 0.14054646, 0.1395888, 0.1353251]\n","epochs:18\n","discriminator loss:[0.32969403 0.356875  ]\n","generator loss:[4.1693873, 0.41184103, 0.44993222, 0.15327854, 0.15035775, 0.14309092, 0.12816028]\n","epochs:19\n","discriminator loss:[0.30158174 0.46355468]\n","generator loss:[4.2001038, 0.42395997, 0.48810127, 0.16222605, 0.14038056, 0.12894513, 0.13303106]\n","epochs:20\n","discriminator loss:[0.35210803 0.31273437]\n","generator loss:[4.508706, 0.38396323, 0.42852956, 0.17599128, 0.16548716, 0.15473868, 0.12668969]\n","epochs:21\n","discriminator loss:[0.2908548 0.4954297]\n","generator loss:[3.9793155, 0.47549924, 0.4800299, 0.1491479, 0.12811148, 0.12580217, 0.12539034]\n","epochs:22\n","discriminator loss:[0.3236459  0.36363283]\n","generator loss:[3.720809, 0.41707513, 0.44046608, 0.13556732, 0.12626183, 0.12463739, 0.12033898]\n","epochs:23\n","discriminator loss:[0.3000453 0.4407422]\n","generator loss:[3.546948, 0.42183232, 0.45887634, 0.13007888, 0.11259675, 0.12014194, 0.119340904]\n","epochs:24\n","discriminator loss:[0.30741584 0.4090625 ]\n","generator loss:[3.4655643, 0.4152528, 0.45814446, 0.12498971, 0.11031055, 0.12056385, 0.118600644]\n","epochs:25\n","discriminator loss:[0.28962064 0.46925783]\n","generator loss:[3.4527853, 0.43787783, 0.45904374, 0.12358663, 0.10808212, 0.118312985, 0.12086296]\n","epochs:26\n","discriminator loss:[0.33760917 0.30742186]\n","generator loss:[4.54461, 0.445617, 0.47844982, 0.17025176, 0.16483986, 0.14184198, 0.1277854]\n","epochs:27\n","discriminator loss:[0.27381524 0.53527343]\n","generator loss:[4.211426, 0.5182642, 0.53264445, 0.16317108, 0.12574865, 0.14602514, 0.12529463]\n","epochs:28\n","discriminator loss:[0.31948918 0.37515625]\n","generator loss:[3.6592402, 0.3964193, 0.46729583, 0.13374968, 0.1213101, 0.12414248, 0.12078503]\n","epochs:29\n","discriminator loss:[0.28799286 0.46839845]\n","generator loss:[3.3587108, 0.41016445, 0.47004738, 0.11668764, 0.10722763, 0.12153175, 0.11781447]\n","epochs:30\n","discriminator loss:[0.27913743 0.48683593]\n","generator loss:[3.3908968, 0.41879317, 0.47187284, 0.122853614, 0.10274379, 0.12473008, 0.11952658]\n","epochs:31\n","discriminator loss:[0.28737694 0.44703126]\n","generator loss:[3.3327684, 0.40184134, 0.46177936, 0.11678596, 0.10653145, 0.118514, 0.117459506]\n","epochs:32\n","discriminator loss:[0.27126303 0.506875  ]\n","generator loss:[3.2158844, 0.43280298, 0.47946507, 0.10886466, 0.097983904, 0.1155268, 0.11960377]\n","epochs:33\n","discriminator loss:[0.27697194 0.49503905]\n","generator loss:[3.2393646, 0.43220273, 0.5182688, 0.1052977, 0.10062978, 0.11298028, 0.116637886]\n","epochs:34\n","discriminator loss:[0.34810668 0.43585938]\n","generator loss:[3.8503284, 0.49180493, 0.5097418, 0.13484848, 0.12487973, 0.12657593, 0.12492382]\n","epochs:35\n","discriminator loss:[0.3161365  0.39328125]\n","generator loss:[3.5583494, 0.44719666, 0.47660145, 0.1254139, 0.11454739, 0.12144293, 0.11349524]\n","epochs:36\n","discriminator loss:[0.27658302 0.4963672 ]\n","generator loss:[3.180993, 0.45921624, 0.4795254, 0.10071161, 0.10145903, 0.10583493, 0.11471007]\n","epochs:37\n","discriminator loss:[0.28693005 0.42492187]\n","generator loss:[3.3890283, 0.40818778, 0.5365025, 0.10892974, 0.11321356, 0.11311967, 0.109785646]\n","epochs:38\n","discriminator loss:[0.257519  0.5384375]\n","generator loss:[3.4315212, 0.41092664, 0.52592105, 0.11991284, 0.10647576, 0.10752715, 0.123260304]\n","epochs:39\n","discriminator loss:[0.33577538 0.34039062]\n","generator loss:[4.2455044, 0.3810195, 0.5994722, 0.16597323, 0.13531926, 0.13847029, 0.11361733]\n","epochs:40\n","discriminator loss:[0.26917726 0.5320313 ]\n","generator loss:[3.9018204, 0.47922558, 0.5762666, 0.12326672, 0.13884538, 0.107095316, 0.11811195]\n","epochs:41\n","discriminator loss:[0.3468474 0.3430078]\n","generator loss:[3.4407127, 0.4272538, 0.6365199, 0.111357965, 0.104390055, 0.11040295, 0.10905587]\n","epochs:42\n","discriminator loss:[0.27935627 0.5144531 ]\n","generator loss:[3.3005476, 0.39063293, 0.5935302, 0.10930466, 0.10075775, 0.10764676, 0.108113654]\n","epochs:43\n","discriminator loss:[0.28489614 0.5054687 ]\n","generator loss:[2.9892442, 0.37172997, 0.5074171, 0.09606681, 0.094382435, 0.09921005, 0.10639473]\n","epochs:44\n","discriminator loss:[0.27801067 0.4632422 ]\n","generator loss:[3.0697274, 0.38910162, 0.5613302, 0.09561008, 0.09549067, 0.10124066, 0.10704759]\n","epochs:45\n","discriminator loss:[0.25509217 0.54945314]\n","generator loss:[2.9683728, 0.39908078, 0.53212446, 0.09065394, 0.09226925, 0.10055384, 0.10738179]\n","epochs:46\n","discriminator loss:[0.26508403 0.5347656 ]\n","generator loss:[2.9733994, 0.3998074, 0.46077132, 0.09490272, 0.094887584, 0.09764201, 0.11727572]\n","epochs:47\n","discriminator loss:[0.26860255 0.5128516 ]\n","generator loss:[3.655131, 0.3744071, 0.47857535, 0.13650216, 0.12062811, 0.12234399, 0.108502105]\n","epochs:48\n","discriminator loss:[0.23493022 0.61757815]\n","generator loss:[3.4359431, 0.44568947, 0.5265225, 0.10777593, 0.11693512, 0.10134626, 0.11527476]\n","epochs:49\n","discriminator loss:[0.2437087 0.5872656]\n","generator loss:[2.96879, 0.37688363, 0.5097113, 0.09136087, 0.09557376, 0.103946716, 0.10890225]\n","epochs:50\n","discriminator loss:[0.2405476 0.5973047]\n","generator loss:[2.88497, 0.37445495, 0.5343759, 0.08618658, 0.09012125, 0.10375487, 0.10930607]\n","epochs:51\n","discriminator loss:[0.23521824 0.60914063]\n","generator loss:[2.8869543, 0.37981597, 0.54586077, 0.083925076, 0.09076012, 0.10004138, 0.11438449]\n","epochs:52\n","discriminator loss:[0.24741945 0.57058597]\n","generator loss:[2.8714614, 0.3676268, 0.56515145, 0.082261235, 0.089928254, 0.10539284, 0.11139527]\n","epochs:53\n","discriminator loss:[0.23915386 0.59117186]\n","generator loss:[3.1015062, 0.38849667, 0.5451933, 0.09898431, 0.09482864, 0.1029281, 0.12675859]\n","epochs:54\n","discriminator loss:[0.25954646 0.53085935]\n","generator loss:[3.9026241, 0.35302746, 0.6217088, 0.14863603, 0.11960548, 0.13775867, 0.107714064]\n","epochs:55\n","discriminator loss:[0.22760291 0.61652344]\n","generator loss:[3.3442962, 0.42074206, 0.5738797, 0.096602984, 0.11601829, 0.10355106, 0.119910754]\n","epochs:56\n","discriminator loss:[0.25104776 0.5524219 ]\n","generator loss:[3.3250082, 0.39351562, 0.69808507, 0.10189741, 0.099378236, 0.10768483, 0.11296632]\n","epochs:57\n","discriminator loss:[0.24152055 0.5644922 ]\n","generator loss:[3.024989, 0.36976025, 0.6212356, 0.08904007, 0.09308037, 0.10480172, 0.107986815]\n","epochs:58\n","discriminator loss:[0.27868828 0.50933594]\n","generator loss:[2.964852, 0.36882916, 0.56729454, 0.08452671, 0.09622002, 0.10031452, 0.12094644]\n","epochs:59\n","discriminator loss:[0.24771404 0.5608594 ]\n","generator loss:[2.9683623, 0.36162332, 0.537086, 0.09060346, 0.09472293, 0.111486815, 0.104902364]\n","epochs:60\n","discriminator loss:[0.2789909  0.50699216]\n","generator loss:[3.157848, 0.39195573, 0.554548, 0.09678689, 0.10144672, 0.09767562, 0.13133231]\n","epochs:61\n","discriminator loss:[0.24707088 0.5539453 ]\n","generator loss:[3.4344952, 0.35017732, 0.570177, 0.1143463, 0.11422971, 0.12076582, 0.10761473]\n","epochs:62\n","discriminator loss:[0.2366938  0.59749997]\n","generator loss:[2.8992739, 0.39572552, 0.59644943, 0.08136061, 0.08773193, 0.0981349, 0.11803845]\n","epochs:63\n","discriminator loss:[0.21560125 0.6454687 ]\n","generator loss:[2.736659, 0.37336627, 0.5619941, 0.076724224, 0.08193146, 0.102002814, 0.11273882]\n","epochs:64\n","discriminator loss:[0.22021216 0.63507813]\n","generator loss:[2.7341766, 0.3629219, 0.57059413, 0.076059245, 0.082515806, 0.10456646, 0.11034357]\n","epochs:65\n","discriminator loss:[0.21001258 0.66296875]\n","generator loss:[2.7977226, 0.37814417, 0.59028274, 0.076698944, 0.08408905, 0.100132264, 0.121283606]\n","epochs:66\n","discriminator loss:[0.22001716 0.6301172 ]\n","generator loss:[2.8280804, 0.35961857, 0.5796965, 0.0798109, 0.08695007, 0.11021636, 0.11093931]\n","epochs:67\n","discriminator loss:[0.2115044  0.65660155]\n","generator loss:[2.9953902, 0.38707775, 0.58816123, 0.089879476, 0.08881065, 0.10200415, 0.1312459]\n","epochs:68\n","discriminator loss:[0.2206552 0.6179688]\n","generator loss:[3.3591282, 0.35233715, 0.6012845, 0.11444893, 0.102526255, 0.12761962, 0.108134955]\n","epochs:69\n","discriminator loss:[0.2076002 0.6620313]\n","generator loss:[3.0422635, 0.39791557, 0.6133308, 0.08062898, 0.09954415, 0.10209898, 0.12718666]\n","epochs:70\n","discriminator loss:[0.22061943 0.62726563]\n","generator loss:[3.1688576, 0.37398106, 0.6231406, 0.09231257, 0.10178111, 0.10923147, 0.12156773]\n","epochs:71\n","discriminator loss:[0.2201466  0.62679684]\n","generator loss:[2.8024852, 0.36800498, 0.5901223, 0.07636094, 0.08538322, 0.11241678, 0.11449954]\n","epochs:72\n","discriminator loss:[0.22462684 0.62199223]\n","generator loss:[3.032837, 0.37993476, 0.6252599, 0.08056248, 0.09776714, 0.10368106, 0.14066514]\n","epochs:73\n","discriminator loss:[0.22221787 0.6164453 ]\n","generator loss:[2.9040227, 0.3605783, 0.6051038, 0.0816694, 0.0894129, 0.11730266, 0.110215016]\n","epochs:74\n","discriminator loss:[0.21629804 0.64175785]\n","generator loss:[2.932904, 0.3834357, 0.6312684, 0.083564594, 0.0846518, 0.10443087, 0.13160516]\n","epochs:75\n","discriminator loss:[0.22280636 0.6148047 ]\n","generator loss:[3.0713189, 0.35684827, 0.65175664, 0.09122408, 0.09226772, 0.11906426, 0.108731575]\n","epochs:76\n","discriminator loss:[0.21351567 0.6471094 ]\n","generator loss:[2.846967, 0.38833675, 0.64253074, 0.07412767, 0.084738284, 0.10265435, 0.1247857]\n","epochs:77\n","discriminator loss:[0.20924422 0.6491797 ]\n","generator loss:[2.7915792, 0.36966118, 0.6332978, 0.07302787, 0.08325462, 0.10998844, 0.11580677]\n","epochs:78\n","discriminator loss:[0.2316655 0.6024219]\n","generator loss:[2.7314005, 0.37094063, 0.6644031, 0.06780058, 0.078716524, 0.10844986, 0.122435704]\n","epochs:79\n","discriminator loss:[0.24108425 0.579414  ]\n","generator loss:[2.7031972, 0.36918223, 0.5900663, 0.0685016, 0.082018875, 0.10851861, 0.13022536]\n","epochs:80\n","discriminator loss:[0.23756173 0.58867186]\n","generator loss:[2.6317198, 0.36373374, 0.58389276, 0.06695442, 0.077696286, 0.113625005, 0.123961315]\n","epochs:81\n","discriminator loss:[0.26327828 0.5449219 ]\n","generator loss:[2.8272674, 0.37641487, 0.63744295, 0.07278361, 0.08367668, 0.10896564, 0.13984112]\n","epochs:82\n","discriminator loss:[0.2557297  0.51789063]\n","generator loss:[3.534537, 0.35148373, 0.64574033, 0.11255359, 0.11734447, 0.13286327, 0.10546915]\n","epochs:83\n","discriminator loss:[0.25201377 0.5554297 ]\n","generator loss:[3.3308954, 0.4103178, 0.6277788, 0.09259323, 0.112045966, 0.10228627, 0.14412056]\n","epochs:84\n","discriminator loss:[0.22859702 0.5972656 ]\n","generator loss:[2.9777012, 0.3678158, 0.57851535, 0.085135005, 0.09449934, 0.1263243, 0.10870222]\n","epochs:85\n","discriminator loss:[0.23183072 0.61117184]\n","generator loss:[2.809389, 0.38925168, 0.56140095, 0.08184354, 0.08072958, 0.111797065, 0.12120823]\n","epochs:86\n","discriminator loss:[0.23815566 0.5903125 ]\n","generator loss:[2.9781382, 0.3643494, 0.5872942, 0.09085697, 0.08910524, 0.117928326, 0.1089441]\n","epochs:87\n","discriminator loss:[0.24865422 0.5725    ]\n","generator loss:[2.5780425, 0.37679845, 0.53409463, 0.06877077, 0.075815074, 0.10739699, 0.11389364]\n","epochs:88\n","discriminator loss:[0.2705808  0.53156245]\n","generator loss:[2.7761898, 0.37491664, 0.55853117, 0.08086626, 0.08075705, 0.109165214, 0.117343605]\n","epochs:89\n","discriminator loss:[0.27355817 0.5035156 ]\n","generator loss:[2.7903636, 0.36142552, 0.5228745, 0.082176924, 0.08559323, 0.11461527, 0.11374698]\n","epochs:90\n","discriminator loss:[0.26544487 0.5221875 ]\n","generator loss:[2.6054375, 0.37609565, 0.49444678, 0.07057363, 0.07956553, 0.10627504, 0.12722845]\n","epochs:91\n","discriminator loss:[0.27222174 0.50847656]\n","generator loss:[2.673354, 0.36524272, 0.555852, 0.07112145, 0.08168591, 0.11328608, 0.11089969]\n","epochs:92\n","discriminator loss:[0.25662446 0.53828126]\n","generator loss:[2.526113, 0.3737706, 0.53014857, 0.06618567, 0.07294797, 0.10831982, 0.12253769]\n","epochs:93\n","discriminator loss:[0.27259666 0.4960156 ]\n","generator loss:[2.5906732, 0.36482903, 0.53100544, 0.0715739, 0.075152844, 0.11424971, 0.11332164]\n","epochs:94\n","discriminator loss:[0.26427934 0.52011716]\n","generator loss:[2.8783145, 0.37746727, 0.5799292, 0.08163871, 0.08488772, 0.110001385, 0.14565253]\n","epochs:95\n","discriminator loss:[0.25667664 0.53738284]\n","generator loss:[3.4680831, 0.35197696, 0.54227126, 0.12357338, 0.110534735, 0.12864251, 0.10411119]\n","epochs:96\n","discriminator loss:[0.23598051 0.59753907]\n","generator loss:[3.101515, 0.39438045, 0.56002176, 0.08568151, 0.10697313, 0.10339754, 0.11716887]\n","epochs:97\n","discriminator loss:[0.23235163 0.6028906 ]\n","generator loss:[2.7689738, 0.3847698, 0.5959656, 0.078288116, 0.078564696, 0.106757686, 0.11295271]\n","epochs:98\n","discriminator loss:[0.21887442 0.64171875]\n","generator loss:[2.6475697, 0.37444755, 0.570354, 0.071135074, 0.07774934, 0.108454436, 0.10546947]\n","epochs:99\n","discriminator loss:[0.22937596 0.61476564]\n","generator loss:[2.6094878, 0.3766216, 0.5978871, 0.06785312, 0.07388647, 0.103567906, 0.1140153]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_cgqy1CBfHKI","colab_type":"code","outputId":"6cb24386-5f82-4f3b-9c34-653404c77a8a","executionInfo":{"status":"ok","timestamp":1566269722242,"user_tz":-540,"elapsed":15492,"user":{"displayName":"北島直人","photoUrl":"","userId":"13780393757979971033"}},"colab":{"base_uri":"https://localhost:8080/","height":373}},"source":["gan.save_model()\n","gan.generate(data_num=10,load=True)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["gen:(6, 128, 128, 3)\n","0\n","gen:(6, 128, 128, 3)\n","1\n","gen:(6, 128, 128, 3)\n","2\n","gen:(6, 128, 128, 3)\n","3\n","gen:(6, 128, 128, 3)\n","4\n","gen:(6, 128, 128, 3)\n","5\n","gen:(6, 128, 128, 3)\n","6\n","gen:(6, 128, 128, 3)\n","7\n","gen:(6, 128, 128, 3)\n","8\n","gen:(6, 128, 128, 3)\n","9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QBpOyLHehttk","colab_type":"code","outputId":"79eeb0f9-62dc-4107-be03-ad42081857ab","executionInfo":{"status":"ok","timestamp":1566212296309,"user_tz":-540,"elapsed":1200,"user":{"displayName":"北島直人","photoUrl":"","userId":"13780393757979971033"}},"colab":{"base_uri":"https://localhost:8080/","height":906}},"source":["gan.g_AB.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_9 (InputLayer)            (None, 128, 128, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 64, 64, 32)   1568        input_9[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 32, 32, 64)   32832       leaky_re_lu_25[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)      (None, 32, 32, 64)   0           conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 16, 16, 128)  131200      leaky_re_lu_26[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, 16, 16, 128)  0           conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 8, 8, 256)    524544      leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, 8, 8, 256)    0           conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_9 (UpSampling2D)  (None, 16, 16, 256)  0           leaky_re_lu_28[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 16, 16, 128)  524416      up_sampling2d_9[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 16, 16, 256)  0           conv2d_41[0][0]                  \n","                                                                 leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","up_sampling2d_10 (UpSampling2D) (None, 32, 32, 256)  0           concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 32, 32, 64)   262208      up_sampling2d_10[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 32, 32, 128)  0           conv2d_42[0][0]                  \n","                                                                 leaky_re_lu_26[0][0]             \n","__________________________________________________________________________________________________\n","up_sampling2d_11 (UpSampling2D) (None, 64, 64, 128)  0           concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 64, 64, 32)   65568       up_sampling2d_11[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 64, 64, 64)   0           conv2d_43[0][0]                  \n","                                                                 leaky_re_lu_25[0][0]             \n","__________________________________________________________________________________________________\n","up_sampling2d_12 (UpSampling2D) (None, 128, 128, 64) 0           concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 128, 128, 3)  3075        up_sampling2d_12[0][0]           \n","==================================================================================================\n","Total params: 1,545,411\n","Trainable params: 1,545,411\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y_oydLuChona","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}